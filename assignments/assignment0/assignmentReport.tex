\documentclass[11pt]{article}
\usep
\begin{docackage{graphicx}
\usepackage{epstopdf}
\usepackage{booktabs}
\usepackage[table]{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{adjustbox}
\usepackage{amsmath}
ument}
\section*{Computer Vision Assignment 3}
\section*{Vaishali Pal \\ 201407665}
\section{Discussion on Recent Sucsess of deep learning}
One of the recent success of deep learning in computer vision area is in learning 3D shape descriptors. Shape descriptor is a concise yet informative representation that provides a 3D object with an identification as a member of some category. The paper chosen for this application is "3D Deep Shape Descriptor" by Yi Fang, Jin Xie, Guoxian, Meng Wang, et all from CVPR2015. 

\subsection{Novelties Introduced in the paper}
The paper provided a unified framework based on deep neural network for learning 3D deep shape descriptors with the application in 3D shape retrieval. 
\begin{enumerate}
\item Novel techniques have been developed to extract concise and geometrically informative shape descriptors and new methods of defining Eigen-shape descriptor and Fisher-shape descriptor to guide the training of a deep neural network. 
\item The deep shape descriptor tends to maximize the inter-class margin while minimize the intra-class variance.
\item It addresses the challenges posed by the high complexity of 3D model and data representation, and the structural variations and noise present in 3D models. 
\end{enumerate}
\subsection{The architecture of the network}
\begin{figure}[h]
\centerline{\includegraphics[scale=.5]{shapedes1.png}}
	\caption{Architecture}
\label{fig:shapedes1}	
\end{figure}
The network uses the architecture of a many-to one encoder neural network to develop the encoder for deep shape descriptor.
\begin{enumerate}
\item A many-to-one encoder forces the
inputs from the same class to be mapped to a unique target value, which is different from the original auto-encoder that sets the target value to be identical to the input. 
\item Thus, the deep shape descriptor represented by the neurons in the hidden layer is invariant to within-group structural variations but will discriminate against other groups.
\item  A new training method is used by setting target value as pre-computed Eigenshape descriptor and Fisher-shape descriptor for each group. 
\item The objective function for the many to one encoder is 
\begin{center}
\begin{math} 
hi(x) = \smash{\displaystyle argmin_{W,b}} \dfrac{1}{2} \sum_{i,j} \|Y_{i} - h(x_{i}^j,W,b)\|_{2}^2 + \dfrac{\lambda}{2} \|W\|_{F}^2
\end{math}
\end{center}
\item  For each group of shapes, two encoders will be trained: one is trained by setting the target value Yi as the i-th ESD and the other is trained by setting the target value Yi as the i-th FSD.
\end{enumerate}

\subsection{Assumptions made regarding the problem to be solved}
\begin{enumerate}
\item Heat kernel signatures(HKS) and heat shape descriptors(HeatSD) are used in the architecture. These are point based signatures that do not provide  global description of the entire shape.
\item HeatSD is a multi-scale descriptor providing local to global description of 3D shapes.
\end{enumerate}
\subsection{Superiority to other baseline methods}
DeepSD demonstrates a better retrieval performance as shown in \ref{fig:shapecom2} than HeatSD. \ref{fig:shapecom1} shows a clear advantage gain of DeepSD over HKS-Covariance Descriptor as hand-crafted shape descriptor is not effective enough in capturing the common geometric features for a collection of 3D models with large structural variations. DeepSD performs reasonably better than ShapeGoogle. This might be because bag-of-words technique uses k-means clustering to construct geometric words.

\begin{figure}[h]
\centerline{\includegraphics[scale=.5]{shapedes2.png}}
	\caption{Comaprison with other methods}
\label{fig:shapecom1}	
\end{figure}
\begin{figure}[h]
\centerline{\includegraphics[scale=.5]{shapedes3.png}}
	\caption{Comparison with other methods}
\label{fig:shapecom2}	
\end{figure}

\subsection{Possible drawbacks}
The datasets SHREC10 and tosca datasets on which the experiments are performed comprises artificial shapes with many of the real world occlusions are noise not present. Real-world 3D shapes extracted from sensors and camera might produce low results than that found in the experiments.

\subsection{Extension to this application or some other application}
The proposed techniques can be extended to 2D images and sketches. It can also be used in 3D geometry for analysis and synthesis of 3D shape families as proposed in a similar paper "Analysis and synthesis of 3D shape families via deep-learned generative models of surfaces"(Eurographics Symposium on Geometry Processing 2015).

\section{CNN using raw pixels and Softmax classifier}

\subsection{Train Set Accuracy}
The train set accuracy of raw pixels with softmax classifier is 83.1180$\%$.

\subsection{Train Set Accuracy of each labels}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
Labels & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\hline
Accuracy & 85.53 & 92.02 & 76.06 & 70.31 & 79.80 & 75.61 & 87.73 & 87.76 & 86.90 & 89.49 \\
\hline
\end{tabular}
  \captionof{table}{Train Set per label accuracy with raw pixels and softmax classifier}
\label{table:1}

\subsection{Train Set Confusion Matrix}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}

\hline
4145 &    49  &  203  &   93 &    65 &    9 &    18 &   41 &   283 &   94 \\
\hline
47 &  4496  &   16  &   32 &     5 &   13 &    38 &   10 &   131 &  212  \\
\hline
259 &     7  & 3946  &  148 &   235 &  134 &   151 &   64 &    47 &    9  \\
\hline
78 &    18  &  200  & 3425 &   187 &  721 &   189 &   84 &    55 &   43 \\
\hline
71 &     2  &  217  &  162 &  4175 &   79 &    92 &  165 &    23 &   14 \\
\hline
19 &    13  &  233  &  659 &   155 & 3652 &    64 &  174 &    12 &   19 \\
\hline
15 &    18  &  207  &  148 &   114 &   46 &  4404 &    9 &    29 &   10 \\
\hline
47 &     7  &  123  &  129 &   264 &  153 &    17 & 4182 &    18 &   60 \\
\hline
91 &    45  &   22  &   41 &    19 &   11 &    37 &   12 &  4657 &   65 \\
\hline
74 &   231  &   21  &   34 &    13 &   12 &    10 &   24 &   104 & 4477 \\
\hline
\end{tabular}
\captionof{table}{Train Set  Confusion Matrix for raw pixels CNN and softmax classifier}
\label{table:2}

\subsection{Test Set Accuracy}
The test set accuracy with softmax classifier is 76.49$\%$

\subsection{Test Set Accuracy of each labels}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
Labels & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\hline
Accuracy & 77.74 & 85.66 & 68.21 & 64.19 & 71.24 & 69.48 & 81.55 & 80.51 & 80.99 & 84.98 \\
 \hline
 \end{tabular}
  \captionof{table}{Test Set per label accuracy with raw pixels and softmax classifier}
 \label{table:3}
 
\subsection{Test Set Confusion Matrix}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline 
 758 &   18 &   39 &   20 &   16 &    8 &   10  &   10 &   94 &    27 \\
 \hline 
14  & 854  &   6  &  10  &   5  &   3  &   9   &   7  &  35  &   57 \\
\hline 
71  &   1  & 691  &  35  &  69  &  54  &  43   &  26  &   5  &    5 \\
\hline 
22  &   8  &  59  & 604  &  63  & 143  &  49   &  27  &  12  &   13 \\
\hline 
16  &   0  &  62  &  33  & 773  &  18  &  44   &  40  &  11  &    3 \\
\hline
8  &   2  &  61  & 136  &  44  & 676  &  16   &  47  &   4  &    6 \\
\hline 
12  &   7  &  51  &  34  &  29  &  10  & 840   &   7  &   9  &    1 \\
\hline 
18  &   6  &  31  &  38  &  73  &  54  &   6   & 756  &   7  &   11 \\
\hline 
39  &  22  &   9  &  18  &   6  &   3  &   7   &   7  & 865  &   24 \\
\hline 
17  &  79  &   4  &  13  &   7  &   4  &   6   &  12  &  26  &  832 \\
\hline
\end{tabular} 
\captionof{table}{Test Set  Confusion Matrix for raw pixels CNN and softmax classifier}

\label{table:4}

\section{CNN using SVM}
\subsection{Train Set Accuracy}
The train Set accuracy of SVM classifier is 83.20$\%$.

\subsection{Train Set Accuracy of each labels}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
Labels & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\hline
Accuracy & 84.83 & 94.97 & 82.52 & 63.77 & 79.17 & 75.61 & 85.44 & 86.07 & 88.04 & 92.04 \\
 \hline
 \end{tabular}
  \captionof{table}{Train Set per label accuracy with CNN and SVM classifier}
 \label{table:5}
 
 \subsection{Train Set Confusion Matrix}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline 
 179  &     2 &   3 &   2 &   4 &   0 &   0 &   1  &  10  &   1 \\ 
 \hline 
  2  &   170 &   0 &   2 &   0 &   1 &   3 &   2  &   5  &   6 \\ 
  \hline 
  7  &     0 & 170 &   5 &   7 &   5 &   4 &   4  &   1  &   0 \\ 
  \hline 
  3  &     1 &   5 & 132 &  11 &  24 &  15 &   2  &   1  &   1 \\ 
  \hline 
  5  &     0 &   5 &  10 & 171 &   6 &   2 &  14  &   0  &   1 \\ 
  \hline 
  1  &     0 &   5 &  39 &   6 & 124 &   2 &   4  &   0  &   2 \\ 
  \hline 
  3  &     0 &  11 &   9 &   5 &   0 & 176 &   0  &   3  &   0 \\ 
  \hline 
  1  &     0 &   6 &   3 &   7 &   3 &   1 & 173  &   2  &   3 \\ 
  \hline 
  8  &     2 &   0 &   1 &   3 &   1 &   2 &   0  & 184  &   2 \\ 
  \hline 
  2  &     4 &   1 &   4 &   2 &   0 &   1 &   1  &   3  & 185 \\ 
\hline 
\end{tabular}
\captionof{table}{Train Set  Confusion Matrix with CNN and SVM classifier}
\label{table:6}

\subsection{Test Set Accuracy}
The test accuracy of SVM classifier is 76.07$\%$ (7607/10000) (classification).


\subsection{Test Set Accuracy of each labels}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
Labels & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\hline
Accuracy & 75.12 & 86.00 & 70.39 & 60.00 & 73.31 & 68.88 & 80.14 & 79.07 & 83.65 & 83.65 \\
 \hline
 \end{tabular}
 \captionof{table}{Test Set per label accuracy with CNN and SVM classifier}
 \label{table:7}
 
 \subsection{Test Set Confusion Matrix}

\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline 
794 &   14  &    35  &    22   &   17  &     2  &     6  &   9  &  73  &  28 \\
\hline
 21 &  848  &     0  &    11   &    4  &     2  &     5  &   6  &  25  &  78 \\
\hline 
 74 &    3  &   642  &    52   &   58  &    69  &    56  &  40  &   3  &   3 \\
\hline 
 20 &    6  &    55  &   597   &   60  &   144  &    59  &  32  &  15  &  12 \\
 \hline
 18 &    1  &    54  &    34   &  772  &    22  &    35  &  52  &   6  &   6 \\
 \hline
 10 &    4  &    40  &   163   &   43  &   675  &    23  &  36  &   4  &   2 \\
 \hline
 10 &    6  &    42  &    56   &   36  &     9  &   819  &   9  &  11  &   2 \\
 \hline
 19 &    3  &    31  &    37   &   56  &    51  &     5  & 782  &   4  &  12 \\
 \hline
 64 &   28  &     7  &    12   &    4  &     2  &     8  &   7  & 849  &  19 \\
 \hline
 27 &   73  &     6  &    11   &    3  &     4  &     6  &  16  &  25  & 829 \\
 \hline
\end{tabular}
\captionof{table}{Test Set  Confusion Matrix with CNN and SVM classifier}
\label{table:8}

\section{Does training a SVM using features from a pre-trained CNN help?}
\begin{tabular}{|c|c|c|c|c|}
\hline
Classifier & Softmax & SVM  \\
\hline
Train Accuracy & 83.118 & 83.20 \\
Test Accuracy & 76.49 & 76.07\\
\hline
\end{tabular}
\label{tab:comparison1}
\vspace{1em} \\
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
Labels & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\hline
Softmax & 77.74 & 85.66 & 68.21 & 64.19 & 71.24 & 69.48 & 81.55 & 80.51 & 80.99 & 84.98 \\
SVM & 75.12 & 86.00 & 70.39 & 60.00 & 73.31 & 68.88 & 80.14 & 79.07 & 83.65 & 83.65 \\
 \hline
\end{tabular}
\label{tab:comparison1}
\vspace{1em} \\
As seen from \ref{tab:comparison1}, softmax out-performs SVM on cross-validation on the training set but produces similar result on the test set. SVM has added complexity which is not required based on the similarity of the accuracies for both the classifiers. One can use softmax in place of SVM for the CIFAR-10 dataset.
\vspace{2em}

\subsection{Visualization of classes using tSNE}
\vspace{1em}

\begin{figure}[h]
\centerline{\includegraphics[scale=.3]{assignment3Server/code/tSNE-epoch-10.eps}}
\vspace{-2em}
	\captionof {figure}{Separability of Classes at Epoch 10}
\label{fig:1_1}	
\end{figure}

\begin{figure}[h]
\centerline{\includegraphics[scale=.3]{assignment3Server/code/tSNE-epoch-20.eps}}
\vspace{-2em}
	\captionof {figure}{Separability of Classes at Epoch 20}
\label{fig:1_2}	
\end{figure}

\begin{figure}[h]
\centerline{\includegraphics[scale=.3]{assignment3Server/code/tSNE-epoch-30.eps}}
\vspace{-2em}
	\captionof {figure}{Separability of Classes at Epoch 30}
\label{fig:1_3}	
\end{figure}

\begin{figure}[h]
\centerline{\includegraphics[scale=.3]{assignment3Server/code/tSNE-epoch-40.eps}}
\vspace{-2em}
	\captionof {figure}{Separability of Classes at Epoch 40}
\label{fig:1_4}	
\end{figure}

\begin{figure}[h]
\centerline{\includegraphics[scale=.3]{assignment3Server/code/tSNE-epoch-50.eps}}
\vspace{-2em}
	\captionof {figure}{Separability of Classes at Epoch 50}
\label{fig:1_5}	
\end{figure}

\begin{figure}[h]
\centerline{\includegraphics[scale=.3]{assignment3Server/code/tSNE-epoch-60.eps}}
\vspace{-2em}
	\captionof {figure}{Separability of Classes at Epoch 60}
\label{fig:1_6}	
\end{figure}

\begin{figure}[h]
\centerline{\includegraphics[scale=.3]{assignment3Server/code/tSNE-epoch-70.eps}}
\vspace{-2em}
	\captionof {figure}{Separability of Classes at Epoch 70}
\label{fig:1_7}	
\end{figure}

\begin{figure}[h]
\centerline{\includegraphics[scale=.3]{assignment3Server/code/tSNE-epoch-80.eps}}
\vspace{-2em}
	\captionof {figure}{Separability of Classes at Epoch 80}
\label{fig:1_8}	
\end{figure}

\begin{figure}[h]
\centerline{\includegraphics[scale=.3]{assignment3Server/code/tSNE-epoch-90.eps}}
\vspace{-2em}
	\captionof {figure}{Separability of Classes at Epoch 90}
\label{fig:1_9}	
\end{figure}

\begin{figure}[h]
\centerline{\includegraphics[scale=.3]{assignment3Server/code/tSNE-epoch-100.eps}}
\vspace{-2em}
 \caption{Separability of Classes at Epoch 100}
\label{fig:1_10}	
\end{figure}
\clearpage

\section{Parameter tuning using CIFAR-100 dataset}


\subsection{Train Set learning rate [1 1]  Accuracy}
The test set accuracy with learning rate 10, 10 for CIFAR-100 is 52.928$\%$

\subsection{Train Set learning rate [1 1] Confusion Matrix}

\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
969 &  301 &    3 &   14 &   27 &   19 &   12 &  102 &   64 &   30  &   78 &  245 & 239  &  59  &   76  &  80  & 128  &   16 &   18  &   20 \\
137 & 1325 &   84 &   34 &   56 &   29 &   23 &  100 &   14 &   17  &   90 &   48 &  48  & 133  &  101  &  59  & 121  &   18 &   36  &   27 \\
  1 &   90 & 1811 &   35 &  199 &    6 &   10 &  145 &    3 &    6  &   21 &    6 &   7  &  25  &   29  &   5  &  34  &   21 &   28  &   18 \\
  7 &   38 &   43 & 1550 &  129 &  215 &  129 &   33 &    7 &   17  &   18 &    8 &   7  &  52  &   77  &   7  &  31  &    5 &   79  &   48 \\
 19 &   65 &  284 &   70 & 1573 &   19 &   11 &   78 &   24 &    4  &   30 &   60 &  25  &  46  &   52  &  14  &  72  &   18 &   20  &   16 \\
 25 &   50 &   21 &  548 &   46 &  900 &  302 &   29 &   19 &   67  &   27 &   29 &  12  &  78  &  104  &  21  &  39  &    5 &  110  &   68 \\
  4 &   52 &   16 &  138 &   29 &  189 & 1625 &   34 &    7 &   54  &   28 &   15 &   6  &  29  &   60  &  10  &  35  &    2 &  111  &   56 \\
 42 &   57 &  140 &   23 &   46 &   17 &   26 & 1541 &   51 &   13  &   30 &   44 &  60  & 105  &   46  &  81  &  40  &   27 &   46  &   65 \\
 97 &    9 &    1 &    8 &   17 &   36 &   11 &   52 & 1019 &   21  &   54 &  436 & 396  &  17  &   76  &  50  & 159  &   16 &    9  &   16 \\
 33 &   38 &    3 &    7 &    4 &   37 &   90 &   18 &    9 & 1668  &  237 &   52 &  10  &   2  &   14  &   8  &   8  &   53 &   98  &  111 \\
 38 &   80 &    6 &   10 &   21 &   14 &   19 &    4 &   24 &  139  & 1962 &   19 &   8  &   8  &    4  &  22  &  19  &   60 &   16  &   27 \\
104 &   21 &    9 &   12 &   28 &   13 &   33 &   58 &  111 &   50  &   45 & 1439 & 177  &  15  &  178  &  25  & 101  &   15 &   35  &   31 \\
129 &   59 &    6 &   16 &    7 &   27 &   11 &  102 &  328 &   16  &   37 &  265 & 959  &  23  &   80  &  52  & 334  &   18 &   11  &   20 \\
 62 &  225 &   62 &  113 &  113 &   89 &   32 &  560 &   66 &   14  &   37 &   45 &  82  & 488  &   62  & 183  &  84  &   21 &  106  &   56 \\
 24 &   32 &   37 &   60 &   47 &   37 &   57 &   46 &   20 &   20  &    9 &   84 &  19  &  24  & 1826  &   5  & 106  &    1 &   25  &   21 \\
205 &  356 &   25 &   25 &   24 &   61 &   29 &  360 &  128 &   23  &   60 &  125 & 175  & 225  &   57  & 344  &  79  &   46 &   90  &   63 \\
141 &  108 &   39 &   27 &   54 &   26 &   40 &  136 &  138 &   13  &   62 &  175 & 483  &  42  &  149  &  43  & 787  &   17 &    7  &   13 \\
 31 &   27 &   28 &    6 &    3 &    7 &    4 &   45 &   15 &   80  &  244 &   24 &  14  &   4  &    3  &  19  &  18  & 1884 &   11  &   33 \\
 12 &   21 &    4 &   21 &    4 &   52 &   39 &   23 &    8 &  127  &   22 &   33 &  11  &  16  &   12  &  17  &   3  &   15 & 1730  &  330 \\
 26 &   33 &   13 &   63 &    6 &   45 &   52 &   87 &   14 &  220  &   88 &   49 &  11  &  26  &   20  &  17  &  12  &   12 &  642  & 1064 \\
\hline
\end{tabular} 
\end{adjustbox}
  \captionof{table}{Train Set per label accuracy for learning rate 1}
\label{table:10}




\subsection{Test set learning rate [1 1] Accuracy}
The test set accuracy with learning rate 10, 10 for CIFAR-100 is 48.79$\%$



\subsection{Test set learning rate [1 1] Confusion Matrix}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
174 &  61 &   0 &   6  &   4 &   4 &   2 &  22 &  12 &  10 &  22 &  49 &  53  & 12 &   16 &   15 &   30 &  2 &   3 &  3   \\
 29 & 235 &  23 &   1  &  11 &   7 &  10 &  27 &   4 &   5 &  25 &  10 &  14  & 18 &   14 &   14 &   37 &  2 &   9 &  5   \\
  1 &  17 & 336 &   9  &  46 &   3 &   5 &  37 &   1 &   0 &   2 &   2 &   3  &  5 &    8 &    1 &    7 &  5 &   6 &  6   \\
  1 &  12 &   8 & 280  &  24 &  43 &  23 &  11 &   2 &   6 &   1 &   3 &   2  & 18 &   19 &    2 &   10 &  1 &  19 & 15   \\
  5 &   9 &  58 &  21  & 295 &   7 &   2 &  25 &  10 &   5 &   4 &  10 &   4  &  8 &    8 &    4 &   12 &  2 &   6 &  5   \\
  3 &   6 &   3 &  94  &  13 & 149 &  77 &   9 &   8 &  18 &  11 &   5 &   6  & 17 &   27 &    4 &    3 &  2 &  38 &  7   \\
  0 &  12 &   7 &  27  &   5 &  36 & 307 &   6 &   1 &  18 &   6 &   3 &   2  &  2 &   11 &    3 &   11 &  0 &  24 & 19   \\
  4 &  18 &  31 &   3  &  14 &   2 &   4 & 286 &  19 &   5 &  10 &  11 &  12  & 19 &   11 &   13 &   14 &  4 &   7 & 13   \\
 26 &   4 &   2 &   5  &   3 &   9 &   3 &  11 & 189 &   2 &   8 &  81 &  82  &  2 &   19 &   14 &   35 &  2 &   1 &  2   \\
  1 &   6 &   1 &   3  &   0 &   8 &  24 &   3 &   3 & 322 &  52 &  10 &   2  &  2 &    1 &    0 &    3 & 11 &  26 & 22   \\
  7 &  15 &   2 &   3  &   5 &   4 &  11 &   3 &   3 &  28 & 380 &   4 &   1  &  2 &    1 &    5 &   11 &  8 &   2 &  5   \\
 29 &   5 &   2 &   5  &   5 &   4 &   6 &  13 &  27 &  19 &  10 & 234 &  53  &  1 &   35 &    6 &   30 &  5 &   4 &  7   \\
 28 &  12 &   1 &   5  &   2 &   8 &   3 &  18 &  53 &   5 &   9 &  76 & 167  &  6 &   18 &   16 &   61 &  6 &   1 &  5   \\
  6 &  42 &  13 &  29  &  19 &  20 &   7 & 119 &  14 &   2 &   7 &  10 &  18  & 96 &   13 &   34 &   17 &  6 &  17 & 11   \\
  6 &   9 &  10 &  14  &  17 &   8 &  12 &   6 &   6 &   5 &   0 &  21 &   5  &  4 &  350 &    1 &   18 &  1 &   5 &  2   \\
 41 &  51 &   5 &  13  &   1 &  10 &   7 &  79 &  28 &   5 &  23 &  32 &  34  & 36 &   14 &   64 &   18 &  3 &  19 & 17   \\
 31 &  28 &   5 &   2  &   9 &   8 &   9 &  25 &  30 &   5 &  18 &  36 &  93  &  5 &   37 &   10 &  141 &  4 &   4 &  0   \\
  4 &   6 &   8 &   3  &   1 &   1 &   0 &   7 &   8 &  26 &  44 &  11 &   0  &  3 &    1 &    6 &   2 & 359 &   3 &  7   \\
  2 &   3 &   3 &   4  &   0 &  17 &  15 &   8 &   2 &  24 &  12 &   5 &   1  &  4 &    2 &    4 &   0 &   2 & 325 & 67   \\
 11 &  17 &   2 &  10  &   0 &  10 &   7 &  23 &   5 &  43 &  12 &  12 &   6  &  4 &    4 &    5 &  2 &    5 & 132 & 190  \\
\hline
\end{tabular} 
\end{adjustbox}
 \captionof{table}{Test Set per label accuracy for learning rate 1}
\label{table:12}



\begin{figure}[h]
\centerline{\includegraphics[scale=.6]{assignment3Server/code/Results/ll1_1e3/epoch25.jpg}}

	\caption{Error and Objective Plot for learning rate [10, 10] on 25th epoch}
\label{fig:1_12}	
\end{figure}
\vspace{2em}


\subsection{Train Set learning rate [10 10]  Accuracy}
The test set accuracy with learning rate 10, 10 for CIFAR-100 is 51.918$\%$

\subsection{Train Set learning rate [10 10] Confusion Matrix}

\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
1329 &  116 &    1 &   24 &   20 &   40 &    21 &   44 &   79 &    85 &    69 &  182 & 127 &  82 &   25  &   85 &  132 &     5 &    6 &   28 \\
 538 &  809 &   91 &   60 &   73 &   54 &    79 &   57 &    7 &    57 &   125 &   39 &  27 & 162 &   78  &   74 &  108 &    12 &   15 &   35 \\
   3 &   40 & 1662 &   66 &  311 &    7 &    39 &  179 &    3 &     7 &     3 &    7 &   2 &  57 &   48  &    4 &   34 &    16 &    6 &    6 \\
  15 &   19 &   19 & 1728 &   80 &  234 &   137 &   22 &   15 &    19 &    23 &   10 &   3 &  54 &   43  &    4 &   10 &     3 &   20 &   42 \\
  15 &   28 &  178 &  135 & 1690 &   21 &    62 &   65 &   31 &     8 &     7 &   35 &  11 &  65 &   43  &   12 &   77 &     7 &    3 &    7 \\
  43 &   21 &    9 &  658 &   47 & 1000 &   290 &   10 &   17 &   116 &    23 &   28 &   7 &  57 &   53  &   14 &   11 &     8 &   32 &   56 \\
  26 &   21 &   12 &  140 &   18 &  162 &  1790 &   17 &   16 &    77 &    33 &    9 &   4 &  29 &   34  &    8 &   18 &     1 &   29 &   56 \\
  68 &   21 &  106 &   49 &   56 &   41 &    52 & 1395 &   48 &    19 &     9 &   36 &  33 & 327 &   22  &   80 &   83 &    16 &    7 &   32 \\
 167 &    7 &    2 &   26 &   17 &   44 &    15 &   43 & 1246 &    25 &    16 &  288 & 282 &  55 &   26  &   40 &  165 &    12 &    7 &   17 \\
  56 &   11 &    0 &   10 &    4 &   41 &    55 &   11 &    6 &  1866 &   158 &   26 &   6 &   5 &    7  &    8 &    4 &    37 &   26 &  163 \\
  69 &   25 &    5 &   16 &   15 &    8 &    32 &   13 &   19 &   232 &  1840 &   15 &  17 &  26 &    1  &   19 &   19 &    84 &    3 &   42 \\
 205 &    8 &    3 &   23 &   44 &   37 &    27 &   52 &  173 &   108 &    52 & 1315 & 137 &  24 &   76  &   25 &  106 &    10 &   13 &   62 \\
 256 &   38 &    5 &   32 &   21 &   57 &    21 &   73 &  412 &    23 &    17 &  206 & 600 &  90 &   37  &   53 &  513 &    19 &    4 &   23 \\
 126 &   83 &   66 &  182 &  127 &  116 &    87 &  484 &   77 &    28 &    15 &   31 &  34 & 659 &   28  &  161 &   97 &    21 &   31 &   47 \\
  66 &   29 &   28 &   76 &   63 &   98 &    90 &   36 &   32 &    30 &    12 &  137 &  10 &  36 & 1638  &    6 &   81 &     2 &    7 &   23 \\
 362 &  159 &   23 &   68 &   54 &   99 &    58 &  295 &  114 &    52 &    34 &   81 &  92 & 412 &   23  &  327 &  115 &    47 &   18 &   67 \\
 263 &   72 &   17 &   53 &   94 &   54 &    90 &   93 &  165 &    37 &    29 &  175 & 289 &  97 &  119  &   63 &  764 &    12 &    3 &   11 \\
  42 &   13 &   24 &    9 &   11 &    5 &     5 &   41 &   14 &   145 &   129 &   15 &  13 &  17 &    0  &   28 &    7 &  1953 &    0 &   29 \\
  18 &   17 &    6 &   88 &    5 &  153 &    57 &   48 &   12 &   182 &    12 &   21 &   3 &  51 &    7  &   28 &    4 &    10 & 1120 &  658 \\
  59 &   21 &   13 &   91 &   12 &   83 &    89 &   96 &   19 &   319 &    70 &   28 &   9 &  35 &   15  &   30 &    5 &    23 &  255 & 1228 \\
\hline
\end{tabular} 
\end{adjustbox}
  \captionof{table}{Train Set per label accuracy for learning rate 10}
\label{table:10}




\subsection{Test set learning rate [10 10] Accuracy}
The test set accuracy with learning rate 10, 10 for CIFAR-100 is 48.16$\%$

\subsection{Test set learning rate [10 10] Confusion Matrix}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
251 &  23 &   0 &   6  &   1  &   8  &   9  &  10  &  14  &  23  &  23  &  31  &  32 &  17  &   6  &  13  &  26 &   1  &   1 &   5 \\
104 & 143 &  22 &  14  &  14  &   9  &  16  &  12  &   5  &  22  &  28  &  14  &   4 &  31  &  18  &  11  &  21 &   3  &   3 &   6 \\
  0 &   6 & 318 &  18  &  64  &   2  &   5  &  40  &   2  &   4  &   1  &   2  &   1 &   8  &  11  &   0  &  11 &   5  &   1 &   1 \\
  5 &   6 &   4 & 306  &  17  &  52  &  29  &   6  &   5  &   7  &   4  &   2  &   1 &  21  &  13  &   1  &   2 &   1  &   4 &  14 \\
  6 &   6 &  45 &  27  & 298  &   8  &  12  &  22  &  14  &   1  &   3  &   8  &   5 &  16  &   4  &   3  &  18 &   2  &   1 &   1 \\
  9 &   5 &   6 & 123  &   8  & 174  &  64  &   2  &   1  &  25  &   9  &   4  &   2 &  16  &  15  &   8  &   5 &   1  &   5 &  18 \\
  3 &   6 &   1 &  34  &   1  &  34  & 345  &   9  &   4  &  15  &   5  &   3  &   4 &   3  &  10  &   2  &   2 &   2  &   5 &  12 \\
 12 &   4 &  20 &   7  &  19  &  11  &  12  & 242  &  12  &   6  &   3  &   8  &   9 &  60  &   9  &  20  &  22 &   6  &   3 &  15 \\
 34 &   3 &   3 &   7  &   5  &  10  &   4  &  10  & 223  &   5  &   3  &  69  &  53 &   7  &  13  &   9  &  38 &   0  &   1 &   3 \\
  8 &   3 &   0 &   2  &   0  &  11  &  21  &   0  &   2  & 363  &  33  &  10  &   1 &   2  &   0  &   2  &   1 &  10  &   3 &  28 \\
 13 &   7 &   3 &   2  &   2  &   4  &   8  &   3  &   6  &  52  & 353  &   6  &   3 &   2  &   0  &   4  &   4 &  19  &   0 &   9 \\
 43 &   2 &   0 &   5  &  10  &  14  &   4  &  13  &  36  &  18  &  10  & 233  &  30 &   7  &  21  &   7  &  25 &   9  &   3 &  10 \\
 50 &   5 &   2 &  13  &   8  &   8  &   3  &  14  &  71  &   6  &   4  &  45  & 107 &  24  &   6  &  17  &  98 &   3  &   5 &  11 \\
 26 &  14 &  14 &  45  &  26  &  21  &  12  & 100  &  18  &   4  &   7  &   8  &   4 & 124  &   8  &  29  &  17 &   6  &   8 &   9 \\
 14 &  4  &  9  & 18   & 21   & 16   & 19   &  5   & 10   &  8   &  0   & 33   &  5  &  10  & 292  &   1  &  23 &   2  &   4 &   6 \\
 72 &  32 &   6 &  18  &   9  &  28  &  12  &  58  &  31  &   9  &   6  &  18  &  20 &  72  &   3  &  56  &  24 &   7  &   7 &  12 \\
 52 &  20 &  10 &  17  &  15  &   7  &  19  &  18  &  37  &  10  &  10  &  36  &  46 &  25  &  26  &  10  & 137 &   4  &   1 &   0 \\
  3 &   2 &   2 &   1  &   5  &   2  &   4  &  15  &   4  &  32  &  22  &   4  &   6 &   5  &   1  &   4  &   2 & 380  &   1 &   5 \\
  3 &   2 &   4 &  15  &   0  &  36  &  11  &   7  &   1  &  43  &   6  &   7  &   0 &  13  &   1  &   4  &   1 &   1  & 232 & 113 \\
 21 &   0 &   4 &  13  &   2  &  14  &  13  &  24  &   5  &  66  &  12  &   8  &   0 &  13  &   3  &   6  &   2 &   3  &  52 & 239 \\
\hline
\end{tabular} 
\end{adjustbox}
  \captionof{table}{Train Set per label accuracy for learning rate 10}
\label{table:12}


\vspace{2em}

\begin{figure}[h]
\centerline{\includegraphics[scale=.6]{assignment3Server/code/Results/ll10_10e3/epoch25.jpg}}

	\caption{Error and Objective Plot for learning rate [10, 10] on 25th epoch}
\label{fig:1_11}	
\end{figure}


\subsection{Train Set learning rate [50 50]  Accuracy}
The test set accuracy with learning rate 10, 10 for CIFAR-100 is 48.7120$\%$


\subsection{Train Set learning rate [50 50] Confusion Matrix}

\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
1283 & 127 &    3 &   43 &   16 &  10 &    7 &  28  &   93  &   44  &   67  &  171 &  358  & 116  &   38  &  2  &   31  &   10 &   19  &   34 \\
 635 & 671 &  113 &   87 &   50 &  35 &   12 &  21  &   17  &   63  &  124  &   27 &   86  & 314  &  113  &  3  &   32  &   21 &   35  &   41 \\
  11 &  44 & 1893 &   97 &  234 &   3 &    4 &  42  &    6  &   11  &   11  &    5 &   17  &  46  &   19  &  0  &    2  &   32 &    5  &   18 \\
  21 &  40 &   52 & 1824 &   70 & 156 &   41 &   9  &   13  &   18  &   21  &    6 &   18  &  51  &   30  &  0  &    5  &    4 &   36  &   85 \\
  32 &  29 &  386 &  159 & 1495 &  12 &   16 &  42  &   27  &   14  &   22  &   31 &   47  &  85  &   35  &  0  &   20  &   16 &   16  &   16 \\
  43 &  33 &   24 &  931 &   38 & 628 &  150 &  17  &   49  &   93  &   31  &   28 &   37  &  88  &   58  &  1  &    8  &    9 &  116  &  118 \\
  23 &  47 &   26 &  468 &   29 & 111 & 1269 &  30  &   19  &  107  &   29  &   13 &    9  &  60  &   62  &  0  &    5  &    5 &  100  &   88 \\
  91 &  49 &  227 &   79 &   90 &  21 &    9 & 834  &   78  &   15  &   16  &   32 &  120  & 661  &   21  &  9  &   18  &   32 &   41  &   57 \\  
 117 &  15 &   12 &   57 &   18 &  13 &    3 &  30  & 1182  &   29  &   39  &  280 &  506  &  78  &   24  &  2  &   26  &   28 &   12  &   29 \\  
  69 &  19 &    3 &   35 &    3 &  28 &   36 &   5  &    8  & 1699  &  124  &   20 &    8  &  24  &    8  &  0  &    0  &   43 &   49  &  319 \\  
  72 &  34 &    9 &   27 &   15 &   7 &   11 &   1  &   17  &  291  & 1819  &    6 &   24  &  18  &    1  &  1  &    5  &   82 &    7  &   53 \\
 172 &  14 &   10 &   45 &   29 &   4 &   18 &  20  &  202  &  127  &   33  & 1230 &  319  &  56  &   82  &  0  &   23  &   17 &   35  &   64 \\
 183 &  44 &   16 &   42 &   20 &  14 &    5 &  34  &  451  &   21  &   40  &  193 & 1083  & 109  &   74  &  2  &   93  &   24 &   14  &   38 \\
 137 & 146 &  109 &  216 &  127 & 105 &   20 & 336  &   75  &   27  &   34  &   19 &  125  & 779  &   44  & 13  &   18  &   39 &   76  &   55 \\
  94 &  35 &   38 &  205 &   54 &  32 &   15 &  22  &   49  &   24  &    4  &   95 &   47  &  37  & 1679  &  3  &   15  &    2 &   16  &   34 \\
 330 & 194 &   28 &   90 &   37 &  64 &   15 & 167  &  154  &   55  &   50  &   63 &  276  & 703  &   47  &  6  &   30  &   72 &   60  &   59 \\
 240 &  90 &   49 &   93 &   83 &  17 &   18 &  43  &  222  &   29  &   62  &  130 &  777  & 171  &  182  &  1  &  232  &   21 &   14  &   26 \\
  15 &  24 &   18 &   21 &   11 &   1 &    2 &  23  &   16  &  134  &  141  &    7 &    6  &  32  &    2  &  5  &    4  & 1981 &    3  &   54 \\
  22 &  13 &   21 &   75 &    3 &  61 &   20 &  17  &   21  &  159  &   13  &   18 &   19  &  52  &    3  &  0  &    1  &   14 & 1544  &  424 \\
  67 &  29 &    6 &  101 &   11 &  37 &   29 &  25  &   16  &  245  &   60  &   16 &   26  &  50  &    8  &  2  &    1  &   20 &  526  & 1225 \\
\hline
\end{tabular} 
\end{adjustbox}
\captionof{table}{Train Set per label accuracy for learning rate 50}
\label{table:10}




\subsection{Test set learning rate [50 50] Accuracy}
The test set accuracy with learning rate 10, 10 for CIFAR-100 is 45.84$\%$





\subsection{Test set learning rate [50 50] Confusion Matrix}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
231 &  26 &   0 &   9 &   2 &   5 &   1 &   4 &  15 &  13 &  21 &  33 &  78 &  28 &  11 & 0 &  3 &   7 &   3 &  10 \\
129 & 125 &  19 &  27 &  13 &   4 &   1 &   6 &   6 &  17 &  18 &  11 &  24 &  53 &  23 & 0 &  1 &   5 &  11 &   7 \\
  2 &   8 & 367 &  30 &  41 &   2 &   1 &  15 &   1 &   2 &   3 &   4 &   1 &   9 &   4 & 0 &  1 &   5 &   1 &   3 \\
  1 &   6 &   7 & 339 &  21 &  30 &   6 &   2 &   4 &   9 &   4 &   3 &   5 &  15 &   6 & 0 &  6 &   1 &  15 &  20 \\
  8 &  12 &  72 &  30 & 285 &   4 &   0 &  10 &   5 &   1 &   2 &   7 &  10 &  26 &   6 & 0 & 10 &   9 &   0 &   3 \\
 12 &   9 &   8 & 181 &   8 & 118 &  32 &   1 &  15 &  11 &   8 &   4 &   2 &  18 &  17 & 0 &  1 &   1 &  30 &  24 \\
  8 &   9 &   7 & 104 &   4 &  19 & 249 &   8 &   1 &  21 &  13 &   4 &   1 &  11 &  16 & 0 &  0 &   0 &   7 &  18 \\
 16 &  11 &  35 &  11 &  21 &   5 &   2 & 180 &  17 &   3 &   2 &   9 &  25 & 115 &  15 & 1 &  6 &   6 &   2 &  18 \\
 33 &   2 &   3 &  15 &   5 &   2 &   2 &   8 & 213 &   3 &   9 &  55 & 112 &  12 &  10 & 1 &  7 &   4 &   1 &   3 \\
 11 &   2 &   0 &  17 &   0 &   2 &   9 &   0 &   3 & 312 &  36 &   9 &   3 &   4 &   3 & 0 &  0 &  11 &  10 &  68 \\
 16 &  13 &   3 &  11 &   1 &   3 &   0 &   1 &   2 &  63 & 347 &   3 &   5 &   3 &   1 & 0 &  1 &  16 &   1 &  10 \\
 43 &   4 &   1 &  11 &  11 &   5 &   4 &   4 &  45 &  21 &   8 & 202 &  75 &  13 &  15 & 0 &  7 &   5 &  11 &  15 \\
 49 &   7 &   4 &   9 &   4 &   4 &   0 &   7 &  85 &   5 &   7 &  50 & 198 &  24 &  13 & 1 & 14 &   5 &   6 &   8 \\
 26 &  24 &  18 &  54 &  32 &  20 &   5 &  66 &  22 &   4 &   7 &   4 &  17 & 145 &  11 & 2 &  5 &   8 &  19 &  11 \\
 15 &   9 &  11 &  26 &  12 &  13 &   5 &   3 &   7 &   9 &   0 &  14 &  10 &  12 & 334 & 0 &  4 &   1 &   9 &   6 \\
 69 &  29 &   9 &  24 &   4 &  11 &   4 &  44 &  27 &  10 &   7 &  15 &  64 & 129 &   6 & 1 &  7 &   8 &  21 &  11 \\
 50 &  28 &  11 &  21 &  14 &   5 &   8 &  11 &  44 &  12 &  14 &  36 & 135 &  26 &  33 & 0 & 36 &   7 &   1 &   8 \\
  4 &   3 &   3 &   3 &   1 &   2 &   1 &   7 &   5 &  43 &  30 &   2 &   2 &  10 &   1 & 0 &  0 & 373 &   1 &   9 \\
  8 &   4 &   5 &   9 &   3 &  13 &   2 &   2 &   3 &  48 &   5 &   4 &   3 &   9 &   2 & 0 &  0 &   3 & 293 &  84 \\
 12 &   3 &   2 &  11 &   2 &   9 &   1 &   9 &  10 &  56 &  13 &   5 &   6 &   9 &   1 & 1 &  1 &   8 & 105 & 236 \\

\hline
\end{tabular} 
\end{adjustbox}
\captionof{table}{Test Set per label accuracy for learning rate 50}
\label{table:12}


\begin{figure}[h]
\centerline{\includegraphics[scale=.6]{assignment3Server/code/Results/ll50_50e3/epoch25.jpg}}

	\caption{Error and Objective Plot for learning rate [10, 10] on 25th epoch}
\label{fig:1_12}	
\end{figure}

\section{CNN using raw pixels as features with softmax classifier}

\subsection{Train Set Accuracy}
The train set accuracy with learning rate 10, 10 for CIFAR-100 is 48.742$\%$

\subsection{Train set Confusion Matrix}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
1068  & 254 &   10 &   26 &   11 &   44 &   13 &   64 &  105 &   34 &   67 &  218 & 145 &   31 &   67 &  113 &  158 &   36 &  18 &   18 \\
 273  & 940 &  190 &   47 &   55 &   73 &   37 &   62 &   30 &   38 &   77 &   53 &  37 &  102 &   96 &  148 &  114 &   39 &  48 &   41 \\
   7  &  55 & 1962 &   34 &  153 &    7 &    6 &   95 &    2 &    5 &   11 &    5 &   3 &   27 &   29 &   10 &   20 &   35 &  14 &   20 \\
  12  &  56 &   61 & 1385 &   83 &  311 &  139 &   34 &   23 &   24 &   22 &   28 &   5 &   61 &   78 &   12 &   18 &   12 &  71 &   65 \\
  21  &  39 &  483 &   75 & 1371 &   14 &   21 &   80 &   44 &   10 &   13 &   52 &  30 &   35 &   45 &   29 &   68 &   37 &  15 &   18  \\
  27  &  45 &   44 &  418 &   30 & 1037 &  293 &   35 &   30 &  105 &   46 &   31 &  10 &   34 &   89 &   30 &   14 &   24 &  95 &   63  \\
  15  &  50 &   18 &  102 &   30 &  185 & 1625 &   33 &   18 &   94 &   33 &   31 &   4 &   22 &   79 &   17 &   15 &    6 &  59 &   64  \\
  73  &  63 &  248 &   37 &   50 &   29 &   32 & 1322 &   65 &    8 &    6 &   44 &  36 &  170 &   34 &  127 &   38 &   38 &  31 &   49  \\
 131  &  27 &   16 &   23 &   13 &   32 &   18 &  103 & 1056 &   17 &   33 &  381 & 237 &   31 &   83 &   82 &  151 &   30 &  20 &   16  \\
  49  &  57 &   14 &   17 &    3 &   49 &   82 &   10 &    3 & 1569 &  242 &   81 &   6 &    2 &   15 &    7 &   12 &   76 &  65 &  141  \\
  85  &  81 &   14 &   18 &   14 &    9 &   25 &   11 &   18 &  155 & 1828 &   24 &  11 &    7 &    7 &   18 &   23 &  107 &  13 &   32  \\
 146  &  27 &   22 &   39 &   20 &   22 &   25 &   75 &  229 &  102 &   38 & 1171 & 140 &   16 &  149 &   41 &  127 &   26 &  51 &   34  \\
 224  &  72 &   25 &   17 &   17 &   39 &   18 &  107 &  417 &   18 &   25 &  334 & 493 &   43 &  102 &  138 &  317 &   35 &  28 &   31  \\
  97  & 180 &  157 &  101 &   88 &  103 &   45 &  518 &   76 &   26 &   37 &   39 &  50 &  439 &   87 &  212 &   87 &   41 &  69 &   48  \\
  54  &  44 &   74 &   85 &   49 &   57 &   64 &   50 &   67 &   30 &    9 &  100 &  18 &   25 & 1608 &   19 &   73 &    9 &  26 &   39  \\
 277  & 229 &   58 &   40 &   29 &   68 &   43 &  285 &  148 &   27 &   62 &  129 & 143 &  202 &   64 &  388 &  105 &   81 &  75 &   47  \\
 183  & 152 &   68 &   40 &   67 &   36 &   34 &  141 &  203 &   24 &   37 &  215 & 246 &   61 &  184 &  139 &  591 &   44 &  20 &   15  \\
  38  &  18 &   28 &    6 &    9 &    5 &    7 &   27 &   13 &   74 &  107 &   21 &   6 &   11 &    5 &   16 &   19 & 2049 &  10 &   31  \\
  32  &  13 &   34 &   13 &    3 &   83 &   92 &   41 &   16 &  212 &   48 &   40 &   6 &   34 &   15 &   19 &    2 &   26 &1438 &  333  \\
  30  &  60 &   34 &   82 &   10 &   79 &   90 &   55 &   16 &  251 &  122 &   49 &  12 &   31 &   19 &   31 &    6 &   52 & 440 & 1031  \\
\hline
\end{tabular}
\label{table:14}
\end{adjustbox}

\subsection{Test Set Accuracy}
The test set accuracy with learning rate 10, 10 for CIFAR-100 is 46.12$\%$

\subsection{Train set Confusion Matrix}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
196 &  43  &   2  &   6  &   3  &  13  &   3  &  12  &  22  &   9  &  19  &  42  &  31  &  7  &  12  & 28  &  31  &   11  &   3 &   7 \\
 51 & 179  &  38  &   9  &   6  &  13  &   6  &  20  &   8  &   9  &  10  &  19  &  11  & 18  &  18  & 25  &  29  &    7  &  13 &  11 \\
  0 &  11  &  376 &   9  &  31  &   2  &   4  &  16  &   3  &   1  &   1  &   3  &   0  &  9  &   7  &  4  &   5  &    6  &   4 &   8 \\
  4 &  12  &  14  &  246 &  22  &  66  &  28  &   9  &   7  &   5  &   3  &   4  &   0  & 10  &  21  &  5  &   8  &    2  &  19 &  15 \\
  5 &   3  &  92  &  16  & 263  &   4  &   5  &  22  &  12  &   2  &   2  &  10  &   6  &  6  &  12  &  4  &  22  &    6  &   5 &   3 \\
  9 &   9  &   6  &  81  &   9  & 179  &  80  &   7  &  10  &  19  &  15  &   4  &   4  &  7  &  15  &  4  &   7  &    7  &  15 &  13 \\
  4 &   8  &   4  &  41  &   2  &  34  & 294  &   6  &   1  &  12  &  10  &   4  &   1  &  3  &  28  &  5  &   4  &    3  &  18 &  18 \\
  9 &  17  &  62  &   8  &   9  &   5  &   5  & 242  &  20  &   2  &   3  &   9  &   7  & 39  &   4  & 23  &  12  &   10  &   4 &  10 \\
 31 &   6  &   2  &   4  &   2  &   4  &   3  &  22  & 209  &   4  &   5  &  76  &  48  &  7  &  18  & 13  &  30  &    4  &   7 &   5 \\
  7 &  18  &   3  &   6  &   1  &   9  &  14  &   1  &   1  & 298  &  54  &  13  &   2  &  2  &   5  &  0  &   4  &   15  &  18 &  29 \\
 21 &  20  &   6  &   4  &   5  &   3  &   4  &   4  &   4  &  31  & 340  &  13  &   3  &  1  &   0  &  3  &   2  &   26  &   1 &   9 \\
 32 &   3  &   6  &   5  &   7  &  10  &   3  &  21  &  28  &  17  &   6  & 227  &  44  &  2  &  30  & 11  &  23  &    4  &  11 &  10 \\
 44 &  11  &  11  &   9  &   3  &   4  &   3  &  22  &  79  &   4  &   6  &  70  &  96  &  7  &  17  & 30  &  60  &    4  &  10 &  10 \\
 18 &  31  &  26  &  21  &  24  &  20  &  14  &  98  &  11  &   4  &   8  &   3  &  15  & 83  &  29  & 41  &  27  &    5  &  17 &   5 \\
 14 &   9  &  26  &  12  &  10  &  16  &  14  &  12  &   8  &  10  &   3  &  18  &   3  &  8  & 297  &  5  &  17  &    5  &   5 &   8 \\
 46 &  43  &   8  &   9  &   5  &  13  &   8  &  68  &  31  &   9  &  11  &  23  &  28  & 39  &  13  & 76  &  29  &   17  &  17 &   7 \\
 49 &  30  &  11  &   5  &  12  &  11  &   8  &  18  &  46  &   3  &  13  &  36  &  54  & 14  &  35  & 21  & 118  &    6  &   6 &    4 \\
  7 &   3  &   8  &   2  &   0  &   2  &   4  &   1  &   5  &  19  &  23  &   3  &   2  &  2  &   1  &  3  &   2  &  405  &   0 &    8 \\
  9 &   5  &   7  &   3  &   0  &  14  &  13  &  10  &   3  &  48  &  19  &  12  &   0  &  7  &   1  &  4  &   1  &    3  & 280 &   61 \\
  8 &   5  &   6  &  15  &   2  &  15  &  15  &  12  &  10  &  48  &  20  &  13  &   4  &  9  &   3  & 11  &   2  &   13  &  81 &  208 \\
\hline
\end{tabular}
\label{table:14} 
\end{adjustbox}

\begin{figure}[h]
\centerline{\includegraphics[scale=.6]{assignment3Server/code/Results/e4/epoch25.jpg}}

	\caption{Error and Objective Plot for raw features on 25th epoch}
\label{fig:1_13}	
\end{figure}

\subsection{Comparison of performance of fine-tuning with training from scratch}

\begin{tabular}{|c|c|c|c|c|}
\hline
&Raw Pixelslr[1,1] & Fine-tuned lr[1,1] & Fine-tune lr[10,10] &  Fine-tuned lr[50,50] \\
\hline
Train Accuracy & 48.74 & 52.928 & 51.918 & 48.712\\
Test Accuracy & 46.12 & 48.79 & 48.16 & 45.84\\
\hline
\end{tabular}
\captionof{table}{Accuracy of classifier with learning rates [1 1],[10 10], [50 50], Raw pixels}
\label{tab:comparison2}

As seen from \ref{tab:comparison2}, for both train and test sets fine tuning out-performs raw pixels for the same learning rate and slightly out-performs fine-tuning for other reasonable learning rates. The performance of very high learning rates are slightly low than raw pixels. The conclusion drawn from the experiments is that fine-tuning will perform better than raw-pixels.


\vspace{2em}
\begin{adjustbox}{max width=1.35\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
Labels & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20\\
\hline
Train[1 1] & 46.01 & 44.36 & 68.73 & 55.76 & 64.65 & 48.97 & 63.60 & 43.37 & 49.25 & 64.18 & 61.72 & 44.95 & 34.89 & 34.44 & 60.34 & 32.39 & 35.61 & 83.00 & 53.59 & 50.59 \\
Test[1 1] & 34.254 & 41.37 & 64.62 & 52.14 & 62.24 & 41.62 & 57.49 & 38.75 & 44.47 & 58.23 & 57.93 & 37.44 & 29.93 & 36.36 & 57.47 & 28.96 & 30.52 & 83.49 & 49.92 & 46.57 \\
\hline
Train[10 10] & 35.67 & 51.93 & 73.22 & 48.90 & 61.19 & 42.48 & 57.82 & 45.38 & 49.74 & 54.32 & 68.76 & 48.99 & 35.17 & 28.16 & 70.51 & 30.59 & 32.47 & 84.99 & 69.78 & 46.66 \\
Test[10 10] & 34.43 & 48.81 &  67.23 & 44.28 & 56.76 & 37.10 &  55.47 & 39.67 & 44.51 & 50.49 & 65.13 & 42.44 & 32.13 & 26.05 & 63.48 & 27.05 & 28.60 & 81.72 & 68.24 & 46.23\\
 \hline
Train[50 50] & 35.08 & 39.54 & 62.21 & 38.85 & 61.45 & 46.21 & 74.65 & 47.77 & 43.54 & 53.01 & 66.39 & 51.46 & 27.71 & 22.07 & 66.36 & 12.00 & 40.77 & 80.14 & 56.68 & 43.18\\
Test[50 50] & 31.09 & 37.43 & 62.74 & 35.99 & 58.88 & 42.75 & 74.77 & 46.39 & 40.19 & 47.06 & 62.64 & 42.62 & 25.52 & 21.61 & 63.26 & 14.29 & 32.73 & 77.23 & 53.56 & 41.26\\ 
 \hline
RawTrain & 37.58 & 38.18 & 55.11 & 53.17 & 65.13 & 45.44 & 59.99 & 41.99 & 40.95 & 55.58 & 63.85 & 38.44 & 30.10 & 31.72 & 56.32 & 24.31 & 30.18 & 73.10 & 55.18 & 48.27 \\
RawTest & 34.75 & 38.41 & 52.66 & 48.14 & 63.22 & 40.96 & 55.68 & 38.84 & 40.35 & 53.79 & 59.54 & 37.71 & 26.74 & 29.64 & 52.47 & 24.05 & 27.25 & 72.45 & 52.43 & 46.33 \\
\hline
 \end{tabular}
 \end{adjustbox}
 \captionof{table}{Accuracy of each labels with learning rates [1 1],[10 10], [50 50], Raw pixels}
 
\label{table:labelper} 
\vspace{1em}
Table \ref{table:labelper} shows a comparison of the per label accuracy of fine tuning and raw pixels. It is evident from the table, that fine-tuning with learning rate 1 performs better than raw pixels with the same learning rate. In fine-tuning, we already have some model learnt from 100 epochs on CIFAR-10 and we are tuning the parameters for that model based on the new data CIFAR-100 which has similar distribution of the data. It finds the best set of parameters for the dataset. Using raw pixels, we have trained only 25 epochs, the model wont be as complex as the previous model, so the accuracy slightly suffers. Another advantage of fine-tuning is that the model need not be retrained from scratch and the several layers reused. This reduced training time significantly.


\section{Maxout Networks}

\subsection{Novelties introduced in the paper}
The paper introduces a novel architecture in deep learning called Maxout that is a good approximation to model averaging in deep learning. It facilitates optimization by dropout and improves dropout's model averaging accuracy. Maxout technique provides a new activation function that is  well suited for training with dropout because its approximation is more accurate for maxout units than for tanh units. A two hidden unit maxout network can approximate any continuous function f(v) arbitrarily well on the compact domain C. Maxout propagates variations in the gradient to the lowest layers of a network so that every parameter in the model gets benefited by dropout emulates bagging training more accurately. 

\subsection{Architecture of Maxout Network}
The maxout model is simply a feed-forward achitecture,
such as MLP or deep CNN that uses a new type of activation
function: the maxout unit. \ref{fig:1_13}
\begin{figure}[h]
\centerline{\includegraphics[scale=.6]{architecture1.png}}

	\caption{n MLP containing two maxout units can arbitrarily approximate any continuous function when cardinality of h1 and h2 is high}
\label{fig:1_13}	
\end{figure}

Given an input to a network layer
\begin{math}
x \in R^d
\end{math}
the maxout hidden layer implements the function \\
\begin{center}
\begin{math} 
hi(x) = \smash{\displaystyle\max_{jâˆˆ[1,k]}} z_{ij}
\end{math}
\end{center} \ref{fig:1_14}

\begin{figure}[h]
\centerline{\includegraphics[scale=0.5]{architecture2.png}}
	\caption{Maxout Activation}
\label{fig:1_14}	
\end{figure}

A maxout unit makes a piecewise linear approximation to an arbitrary convex function. It learns the relationship between hidden units and the activation function of each hidden unit. But the representation it produces
is not sparse. Thus dropout will artificially
sparsify the effective representation during training.
Maxout is also not constrained to learn to be bounded at all. Maxout is locally linear almost everywhere as shown in Fig \ref{fig:architecture3}
\begin{figure}[h]
\centerline{\includegraphics[scale = 0.6]{architecture3.png}}
	\caption{Maxout Activation}
\label{fig:architecture3}	
\end{figure}

\subsection{Assumptions about the problem to be solved}
\begin{enumerate}
\item Maxout activations are non-differentiable on a finite set of points.
\item Dropout introduces sparsity in the distribution of the activations, therefore maxout does not need to be sparse.
\item Maxout activation function is designed to never
have a gradient of zero, allowing the network using maxout
and dropout to achieve a good approximation to model
averaging.
\item In Maxout activation units, there must be k sets of points - each set lying in one of the k regions of the activation function domain (Fig. 1). If this assumption is violated, then the activation units may degenerate into simple linear functions that are not capable of exponentially dividing the input space. Thus, there must be a balanced initial
distribution of data points with respect to the domain of
the piecewise linear activation. function\ref{fig:assumption1}
\begin{figure}[h]
\centerline{\includegraphics[scale = 0.6]{assumption1.png}}
	\caption{Maxout Activation}
\label{fig:assumption1}	
\end{figure}
\end{enumerate}

\subsection{Possible Drawbacks of Maxout}
If there are two competing filters in a Maxout unit, one receptive of edge structures whereas the other is receptive of corners. Suppose the first filter has max value(~3) which means Maxout output is also ~3. For another instance, if the other function has max value which is approximately same value ~3. This would input the same value for different detections for a particular feature dimension. Thus the next layer to be able to discern this signal as shown in Figure \ref{fig:drawback1}
\begin{figure}[h]
\centerline{\includegraphics[scale=.5]{drawback1.png}}
	\caption{Maxout Activation}
\label{fig:drawback1}	
\end{figure}

\end{document}
